{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca757f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "from typing import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd1e499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (100, 4)\n",
      "Shape of y: (100,)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "#shape\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "#making the dataset into binary for binary classification\n",
    "binary_filter = y < 2\n",
    "X = X[binary_filter]\n",
    "y = y[binary_filter]\n",
    "\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "\n",
    "X = (X - mean) / std\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e365a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (80, 4)\n",
      "Shape of X_test: (20, 4)\n",
      "Shape of Y_train: (80,)\n",
      "Shape of Y_test: (20,)\n"
     ]
    }
   ],
   "source": [
    "#splitting into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=55)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6906680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T \n",
    "X_test = X_test.T\n",
    "\n",
    "Y_train = Y_train.reshape(1, -1)\n",
    "Y_test = Y_test.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be44bcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4, 80)\n",
      "Shape of X_test: (4, 20)\n",
      "Shape of Y_train: (1, 80)\n",
      "Shape of Y_test: (1, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a07024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X: np.ndarray, Y: np.ndarray, hidden_layers: int = 5) -> Tuple[int, int, int]:\n",
    "    n_x = X.shape[0]  #input layer size\n",
    "    n_y = Y.shape[0]  #output layer size\n",
    "    n_h = hidden_layers  #number of hidden layers\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c7bd2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = layer_sizes(X_train,Y_train)\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3c8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_h = sizes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a61450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x: int, n_h: int, n_y: int) -> Dict[str, np.ndarray]:\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de671da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X: np.ndarray, parameters: Dict[str, np.ndarray]) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    \n",
    "    Z2 = np.clip(Z2, -50, 50)  #to avoid overflow\n",
    "    \n",
    "    A2 = 1 / (1 + np.exp(-Z2))\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd24cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2: np.ndarray, Y: np.ndarray) -> float:\n",
    "    #A2: sigmoid output of the second activation -> (1, number of examples)\n",
    "    m = Y.shape[1]\n",
    "    A2 = np.clip(A2, 1e-10, 1 - 1e-10)  # avoiding log(0)\n",
    "    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), 1 - Y)\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    \n",
    "    cost = float(np.squeeze(cost))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb2dc4",
   "metadata": {},
   "source": [
    "\\[\n",
    "\\begin{align*}\n",
    "dz^{[2]} &= a^{[2]} - y \\\\\n",
    "dW^{[2]} &= dz^{[2]} a^{[1]T} \\\\\n",
    "db^{[2]} &= dz^{[2]} \\\\\n",
    "dz^{[1]} &= W^{[2]T} dz^{[2]} * g^{[1]'}(z^{[1]}) \\\\\n",
    "dW^{[1]} &= dz^{[1]} x^T \\\\\n",
    "db^{[1]} &= dz^{[1]}\n",
    "\\end{align*}\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "\\begin{align*}\n",
    "dZ^{[2]} &= A^{[2]} - Y \\\\\n",
    "dW^{[2]} &= \\frac{1}{m} dZ^{[2]} A^{[1]T} \\\\\n",
    "db^{[2]} &= \\frac{1}{m} \\text{np.sum}(dZ^{[2]}, \\text{axis}=1, \\text{keepdims}=\\text{True}) \\\\\n",
    "dZ^{[1]} &= W^{[2]T} dZ^{[2]} * g^{[1]'}(Z^{[1]}) \\\\\n",
    "dW^{[1]} &= \\frac{1}{m} dZ^{[1]} X^T \\\\\n",
    "db^{[1]} &= \\frac{1}{m} \\text{np.sum}(dZ^{[1]}, \\text{axis}=1, \\text{keepdims}=\\text{True})\n",
    "\\end{align*}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d45cf6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters: Dict[str, np.ndarray], cache: Dict[str, np.ndarray], X: np.ndarray, Y: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "        \n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T) / m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))  #tanh derivative\n",
    "    dW1 = np.dot(dZ1, X.T) / m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc108237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters: Dict[str, np.ndarray], grads: Dict[str, np.ndarray], learning_rate: float = 0.00001) -> Dict[str, np.ndarray]:\n",
    "    W1 = copy.deepcopy(parameters['W1'])\n",
    "    b1 = copy.deepcopy(parameters['b1'])\n",
    "    W2 = copy.deepcopy(parameters['W2'])\n",
    "    b2 = copy.deepcopy(parameters['b2'])\n",
    "    \n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    \n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15924573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X: np.ndarray, Y: np.ndarray, n_h: int, num_iterations: int = 10000, print_cost: bool = True) -> Dict[str, np.ndarray]:\n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)  #forward\n",
    "        cost = compute_cost(A2, Y)  #cost\n",
    "        grads = backward_propagation(parameters, cache, X, Y)  #backward\n",
    "        \n",
    "        parameters = update_parameters(parameters, grads, learning_rate=1.2)\n",
    "    \n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fbaa368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693151\n",
      "Cost after iteration 1000: 0.000181\n",
      "Cost after iteration 2000: 0.000089\n",
      "Cost after iteration 3000: 0.000059\n",
      "Cost after iteration 4000: 0.000044\n",
      "Cost after iteration 5000: 0.000035\n",
      "Cost after iteration 6000: 0.000029\n",
      "Cost after iteration 7000: 0.000025\n",
      "Cost after iteration 8000: 0.000022\n",
      "Cost after iteration 9000: 0.000019\n"
     ]
    }
   ],
   "source": [
    "params = nn_model(X_train, Y_train, n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7256ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters: Dict[str, np.ndarray], X: np.ndarray) -> np.ndarray:\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = (A2 > 0.5).astype(int)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d39d04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(parameters: Dict[str, np.ndarray], X_test: np.ndarray, Y_test: np.ndarray) -> float:\n",
    "    predictions = predict(parameters, X_test)\n",
    "    print(\"Predictions:\", predictions)\n",
    "    print(\"True labels:\", Y_test)\n",
    "    \n",
    "    true_positive = np.sum((predictions == 1) & (Y_test == 1))\n",
    "    true_negative = np.sum((predictions == 0) & (Y_test == 0))\n",
    "    total = Y_test.size\n",
    "    \n",
    "    accuracy = (true_positive + true_negative) / total * 100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8856c8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1]]\n",
      "True labels: [[0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(params, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2457d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
