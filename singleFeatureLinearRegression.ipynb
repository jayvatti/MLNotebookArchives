{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfecf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acfc4e8",
   "metadata": {},
   "source": [
    "## MSE Cost Function\n",
    "Linear Model: $f_{w,b}(x^{(i)})$:\n",
    "$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$\n",
    "\n",
    "Goal: Minimize $w$,$b$  \n",
    "\n",
    "Minimizing error between our predictions $f_{w,b}(x^{(i)})$ and the actual data $y^{(i)}$. The measure is called the $cost$, $J(w,b)$. \n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\\tag{2}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313e98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(x, y, w=0, b=0):\n",
    "    m = x.shape[0] \n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    cost = 1 / (2 * m) * cost\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec74531",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "The gradient:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient_descent(x, y, w, b):\n",
    "    m = x.shape[0]    \n",
    "    derivative_w = 0\n",
    "    derivative_b = 0\n",
    "    \n",
    "    for i in range(m):  \n",
    "        f_wb = w * x[i] + b \n",
    "        derivative_w_i = (f_wb - y[i]) * x[i] \n",
    "        derivative_b_i = f_wb - y[i]\n",
    "        \n",
    "        #simulataneous updating\n",
    "        derivative_b += derivative_b_i\n",
    "        derivative_w += derivative_w_i\n",
    "        \n",
    "    return derivative_w/m, derivative_b/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85459eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data:\n",
    "\n",
    "1 feature : wx + b\n",
    "\n",
    "M examples\n",
    "\n",
    "x: all the x values. \n",
    "y: all the y values. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_initial, b_initial, alpha, iterations, cost_function, gradient_function): \n",
    "    \"\"\"\n",
    "    Return Type:\n",
    "      w (scalar): Updated w with least error (MINIMA)\n",
    "      b (scalar): Updated b with least error (MINIMA)\n",
    "      cost_cache (List): Cost values\n",
    "      values_cache (list): [w,b]\n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    cost_cache = []\n",
    "    values_cache = []\n",
    "    b = b_initial\n",
    "    w = w_initial\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        derivative_w, derivative_b = gradient_function(x, y, w , b) \n",
    "\n",
    "        # updating w and b until convergence\n",
    "        w = w - alpha * derivative_w \n",
    "        b = b - alpha * derivative_b                                  \n",
    "\n",
    "        if i<100000:     \n",
    "            cost_cache.append(cost_function(x, y, w , b))\n",
    "            values_cache.append([w,b])\n",
    "\n",
    "    return w, b, cost_cache, values_cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ccb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/height_weight.csv')\n",
    "\n",
    "#height is independent\n",
    "#weight is dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e7716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_initial = 0\n",
    "b_initial = 0\n",
    "iterations = 10000\n",
    "learning_rate = 6.0e-4\n",
    "\n",
    "x = np.array(df[\"height\"])\n",
    "y = np.array(df[\"weight\"])\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cdcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score Normalization\n",
    "\n",
    "x_mean,x_std = np.mean(x),np.std(x)\n",
    "x_normalized = (x - x_mean) / x_std\n",
    "\n",
    "y_mean,y_std = np.mean(y),np.std(y)\n",
    "y_normalized = (y - y_mean) / y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_final, b_final, cost_cache, values_cache = gradient_descent(x_normalized,y_normalized, w_initial, b_initial, learning_rate, \n",
    "                                                    iterations, calculate_cost, calculate_gradient_descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439dba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: I looked at the Cost Vs Iteration graph and kept changing the learning rate best fit for my data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(cost_cache)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Cost vs. Iteration')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13407adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_new = x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "#training\n",
    "reg.fit(x_new, y)\n",
    "print(\"Intercept: \", reg.intercept_)\n",
    "print(\"Slope: \", reg.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_height = np.array([[70]])  # input must be 2D array\n",
    "predicted_weight = reg.predict(new_height)\n",
    "\n",
    "print(\"Predicted weight: \", predicted_weight)\n",
    "\n",
    "\n",
    "#normalised height = 70\n",
    "height_normalized = (70 - x_mean) / x_std\n",
    "\n",
    "#predicting y \n",
    "weight_normalized_predicted = w_final * height_normalized + b_final\n",
    "\n",
    "# getting back the original denormalised\n",
    "weight_predicted = weight_normalized_predicted * y_std + y_mean\n",
    "\n",
    "print(\"Custom:\",weight_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = reg.score(x_new, y)\n",
    "print(\"R-squared: \", score)\n",
    "\n",
    "#accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(x, y, marker='.', c='b', label=\"Linear Data\")\n",
    "ax.legend( fontsize='large')\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_xlabel('Height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "denormalized_w = normalized_w *  std(y)/std(x) \n",
    "denormalized_b = mean(y) - denormalized_w * mean(x)\n",
    "'''\n",
    "\n",
    "denormalized_w_final = w_final * (np.std(y) / np.std(x))\n",
    "\n",
    "denormalized_b_final = np.mean(y) - (denormalized_w_final * np.mean(x))\n",
    "\n",
    "print(f\"Custom (Denormalization):\\nw: {denormalized_w_final}\\nb:{denormalized_b_final}\\n\")\n",
    "print(f\"Model:\\nw: {reg.coef_[0]}\\nb:{reg.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b619060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the data points (ORIGINAL DATA)\n",
    "plt.scatter(x, y, marker='*', c='b', label=\"Linear Data\")\n",
    "plt.ylabel('Weight')\n",
    "plt.xlabel('Height')\n",
    "\n",
    "\n",
    "# Plotting the linear regression line\n",
    "x_line = np.linspace(min(x), max(x), 100)\n",
    "y_line = denormalized_w_final * x_line + denormalized_b_final\n",
    "plt.plot(x_line, y_line, color='r', label=\"Linear Regression Line\")\n",
    "\n",
    "\n",
    "plt.legend(fontsize='large')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the data points (NORMALIZED DATA)\n",
    "plt.scatter(x_normalized, y_normalized, marker='*', c='b', label=\"Linear Data\")\n",
    "plt.ylabel('Weight')\n",
    "plt.xlabel('Height')\n",
    "\n",
    "# Plotting the linear regression line\n",
    "x_line_normalized = np.linspace(min(x_normalized), max(x_normalized), 100)\n",
    "y_line_normalized = w_final * x_line_normalized + b_final\n",
    "plt.plot(x_line_normalized, y_line_normalized, color='r', label=\"Linear Regression Line (Normalization)\")\n",
    "\n",
    "\n",
    "plt.legend(fontsize='large')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74710776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
